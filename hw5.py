# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VeeW4iTyZq4Qn_647V_9rvvb9CHqTMTl
"""

!pip install --upgrade scikit-learn==1.5.2 xgboost==1.7.6 lightgbm==3.3.5


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor
import xgboost as xgb
import lightgbm as lgb
import warnings
warnings.filterwarnings("ignore", category=UserWarning)

train_data = pd.read_csv("train.csv")
test_data = pd.read_csv("test.csv")

y = np.log1p(train_data["SalePrice"])
X = train_data.drop(columns=["SalePrice", "Id"])
test_ids = test_data["Id"]
test_features = test_data.drop(columns=["Id"])

numeric_features = X.select_dtypes(include=["number"]).columns
categorical_features = X.select_dtypes(include=["object"]).columns

def handle_missing(data):
    data = data.copy()
    for col in numeric_features:
        data[col] = data[col].fillna(data[col].median())
    for col in categorical_features:
        data[col] = data[col].fillna("None")
    return data

X = handle_missing(X)
test_features = handle_missing(test_features)

numeric_transformer = Pipeline(steps=[
    ("scaler", StandardScaler()),
    ("poly", PolynomialFeatures(degree=2, include_bias=False))
])

categorical_transformer = Pipeline(steps=[
    ("onehot", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_features),
        ("cat", categorical_transformer, categorical_features)
    ]
)

X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)

def evaluate_model(pipeline, X_valid, y_valid):
    y_pred = pipeline.predict(X_valid)
    return np.sqrt(mean_squared_error(y_valid, y_pred))

models = {
    "LinearRegression": LinearRegression(),
    "Ridge": Ridge(alpha=10),
    "Lasso": Lasso(alpha=0.001),
    "ElasticNet": ElasticNet(alpha=0.001, l1_ratio=0.5),
    "RandomForest": RandomForestRegressor(n_estimators=300, max_depth=10, random_state=42),
    "GradientBoosting": GradientBoostingRegressor(n_estimators=300, learning_rate=0.05, max_depth=4, random_state=42),
    "XGBoost": xgb.XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=4, random_state=42),
}

stacking_model = StackingRegressor(
    estimators=[
        ("RandomForest", models["RandomForest"]),
        ("GradientBoosting", models["GradientBoosting"]),
        ("XGBoost", models["XGBoost"])
    ],
    final_estimator=Ridge(alpha=10),
    passthrough=True
)
models["Stacking"] = stacking_model

results = {}
for name, model in models.items():
    pipeline = Pipeline(steps=[("preprocessor", preprocessor), ("model", model)])
    pipeline.fit(X_train, y_train)
    rmse = evaluate_model(pipeline, X_valid, y_valid)
    results[name] = rmse
    print(f"{name}: RMSE = {rmse:.4f}")

plt.figure(figsize=(10, 5))
sns.barplot(x=list(results.keys()), y=list(results.values()), palette="viridis")
plt.xticks(rotation=45)
plt.xlabel("Model")
plt.ylabel("RMSE (Log Scale)")
plt.title("Comparison of models")
plt.show()

best_model_name = min(results, key=results.get)
best_model = models[best_model_name]

final_pipeline = Pipeline(steps=[("preprocessor", preprocessor), ("model", best_model)])
final_pipeline.fit(X, y)

test_predictions = np.expm1(final_pipeline.predict(test_features))

submission = pd.DataFrame({"Id": test_ids, "SalePrice": test_predictions})
submission.to_csv("submission.csv", index=False)

print(f"The best model: {best_model_name}")

