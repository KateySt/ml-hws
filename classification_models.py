# -*- coding: utf-8 -*-
"""classification_models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nItxiDpbUAHpVK_ETDIkBKdmlIvq40Wk
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install albumentations datasets > /dev/null

# Import necessary libraries
import os
import sys
import gzip
import struct
from typing import List

import albumentations as albu  # Library for image augmentation
import cv2  # OpenCV library for image processing
import numpy as np
from tqdm import tqdm  # Library for progress bars

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader  # PyTorch utilities for data handling
import torchvision.models as models  # Pre-trained models provided by PyTorch

from datasets import load_dataset  # Custom function to load dataset

import matplotlib.pyplot as plt  # Library for plotting graphs and images

torch.manual_seed(42)  # Set random seed for reproducibility

"""## Dataset - [Tiny ImageNet](https://huggingface.co/datasets/zh-plus/tiny-imagenet)

"""

# Load the dataset using the load_dataset function with parameters "frgfm/imagenette" and "320px".
# The "frgfm/imagenette" dataset is being loaded with images resized to 320 pixels.
dataset = load_dataset("frgfm/imagenette", "320px")

# Define the number of labels in the dataset.
num_labels = 10

# Print the dataset object.
dataset

# Access the training split of the dataset using the key "train".
# Then, access the 124th sample (indexing is 0-based) within the training split.
# Retrieve the image data associated with the sample.
image_data = dataset["train"][123]["image"]

class HuggingFaceDataset(Dataset):
    """
    Define a custom dataset class named HuggingFaceDataset inheriting from the PyTorch Dataset class.
    """
    def __init__(self, dataset: Dataset, augmentations: albu.Compose) -> None:
        # Constructor method to initialize the dataset and augmentation transformations.
        self.dataset = dataset  # Store the input dataset
        self.augs = augmentations  # Store the augmentation transformations

    def __len__(self) -> int:
        # Override the len method to return the length of the dataset.
        return len(self.dataset)

    def __getitem__(self, index) -> tuple:
        # Override the getitem method to retrieve a sample from the dataset.
        sample = self.dataset[index]  # Get the sample at the specified index from the dataset

        # Convert the image to RGB format if it's not already in that format
        image = sample["image"].convert("RGB")

        # Apply the specified augmentations to the image
        image = self.augs(image=np.array(image))["image"]

        # Convert the augmented image to a PyTorch tensor and permute its dimensions
        image = torch.from_numpy(image).permute(2, 0, 1)

        # Convert the label to a PyTorch LongTensor
        label = torch.LongTensor([sample["label"]])

        # Return the augmented image and its corresponding label as a tuple
        return image, label

# Set the batch size for training
batch_size = 32

# Define the input shape for the images (height, width).
# NOTE: To speed up training, you can decrease the input shape, but it may affect the final performance.
input_shape = (224, 224)

# Set the number of workers for data loading to be the number of available CPU cores
workers = os.cpu_count()

# Define the augmentation transformations for training images
# TODO: optional, play with augmentations
train_augs = albu.Compose([
    albu.Resize(input_shape[0], input_shape[1]),
    albu.HorizontalFlip(p=0.5),
    albu.RandomBrightnessContrast(p=0.2),
    albu.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
])

# Create a DataLoader for training data using the defined augmentations
train_loader = DataLoader(
    HuggingFaceDataset(dataset['train'], train_augs),
    batch_size=batch_size,
    shuffle=True,
    num_workers=workers
)

# Define the augmentation transformations for validation images
valid_augs = albu.Compose([
    albu.Resize(input_shape[0], input_shape[1]),
    albu.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
])

# Create a DataLoader for validation data using the defined augmentations
valid_loader = DataLoader(
    HuggingFaceDataset(dataset['validation'], valid_augs),
    batch_size=batch_size,
    shuffle=False,
    num_workers=workers
)

def train_one_epoch(
    model: nn.Module,
    loader: DataLoader,
    criterion: nn.Module,
    optimizer: optim.Optimizer,
    device: str = "cpu",
    verbose: bool = True,
) -> dict:
    """
    Function to train the model for one epoch.

    Args:
    - model: The neural network model to be trained.
    - loader: DataLoader object for loading the training data.
    - criterion: Loss function criterion.
    - optimizer: Optimizer for updating model parameters.
    - device: Device to run the model on (default is "cpu").
    - verbose: If True, print progress during training.

    Returns:
    - logs: Dictionary containing training statistics.
    """
    # TODO: complete training function
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for images, labels in tqdm(loader, desc="Training", leave=False):
        images, labels = images.to(device), labels.to(device).squeeze()

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    logs = {
        "loss": running_loss / len(loader),
        "accuracy": correct / total,
    }
    if verbose:
        print(f"Train Loss: {logs['loss']:.4f}, Train Accuracy: {logs['accuracy']:.4f}")
    return logs

@torch.inference_mode()
def evaluate(
    model: nn.Module,
    loader: DataLoader,
    criterion: nn.Module,
    device: str = "cpu",
    verbose: bool = True,
) -> dict:
    """
    Function to evaluate the model on the validation or test set.

    Args:
    - model: The neural network model to be evaluated.
    - loader: DataLoader object for loading the validation or test data.
    - criterion: Loss function criterion.
    - device: Device to run the model on (default is "cpu").
    - verbose: If True, print evaluation results.

    Returns:
    - logs: Dictionary containing evaluation statistics.
    """
    # TODO: complete evaluation function
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for images, labels in tqdm(loader, desc="Evaluating", leave=False):
            images, labels = images.to(device), labels.to(device).squeeze()

            outputs = model(images)
            loss = criterion(outputs, labels)

            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    logs = {
        "eval_loss": running_loss / len(loader),
        "accuracy": correct / total,
    }
    if verbose:
        print(f"Validation Loss: {logs['eval_loss']:.4f}, Validation Accuracy: {logs['accuracy']:.4f}")
    return logs

# Check if CUDA (GPU) is available, otherwise use CPU
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Device - {device}\n")

# TODO: Find a model that gives the best score.
# Here, a pre-trained ResNet50 model is used as a starting point.
# You may experiment with other pre-trained models available in torchvision.models.
model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)  # Load pre-trained ResNet18 model
model.fc = nn.Linear(model.fc.in_features, num_labels)  # Replace the fully connected layer with new output size
model = model.to(device)  # Move the model to the specified device (CPU or GPU)

print("Number of trainable parameters -", sum(p.numel() for p in model.parameters() if p.requires_grad))

# Define the optimizer for updating model parameters
optimizer = optim.Adam(model.parameters(), lr=1e-3)

# Define the loss function
loss_fn = nn.CrossEntropyLoss()

n_epochs = 20  # Number of epochs for training

train_losses = []  # List to store training losses for each epoch
train_accuracies = []  # List to store training accuracies for each epoch

valid_losses = []  # List to store validation losses for each epoch
valid_accuracies = []  # List to store validation accuracies for each epoch

# Loop through each epoch
for ep in range(n_epochs):
    print(f"\nEpoch {ep + 1:2d}/{n_epochs:2d}")

    # Train the model for one epoch and collect training statistics
    train_logs = train_one_epoch(model, train_loader, loss_fn, optimizer, device, verbose=True)
    train_losses.append(np.mean(train_logs["loss"]))
    train_accuracies.append(np.mean(train_logs["accuracy"]))
    print("      loss:", train_losses[-1])
    print("  accuracy:", train_accuracies[-1])

    # Evaluate the model on the validation set and collect evaluation statistics
    valid_logs = evaluate(model, valid_loader, loss_fn, device, verbose=True)
    valid_losses.append(np.mean(valid_logs["eval_loss"]))  # Append the validation loss for the epoch
    valid_accuracies.append(np.mean(valid_logs["accuracy"]))  # Append the validation accuracy for the epoch
    print("      loss:", valid_losses[-1])  # Print the validation loss for the epoch
    print("  accuracy:", valid_accuracies[-1])  # Print the validation accuracy for the epoch

# Create a figure with two subplots side by side
fix, axes = plt.subplots(ncols=2, figsize=(15, 4))

# Plot the training and validation losses on the first subplot (axes[0])
axes[0].plot(np.arange(len(train_losses)), train_losses, ".-")  # Plot training losses
axes[0].plot(np.arange(len(valid_losses)), valid_losses, ".-")  # Plot validation losses
axes[0].legend(["train", "validation"])  # Add legend to distinguish between training and validation losses
axes[0].set_title("Loss")  # Set title for the subplot as "Loss"
axes[0].grid()  # Add grid lines to the plot

# Plot the training and validation accuracies on the second subplot (axes[1])
axes[1].plot(np.arange(len(train_accuracies)), train_accuracies, ".-")  # Plot training accuracies
axes[1].plot(np.arange(len(valid_accuracies)), valid_accuracies, ".-")  # Plot validation accuracies
axes[1].legend(["train", "validation"])  # Add legend to distinguish between training and validation accuracies
axes[1].set_title("Accuracy")  # Set title for the subplot as "Accuracy"
axes[1].grid();  # Add grid lines to the plot